{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "public-politics",
   "metadata": {},
   "source": [
    "# Synoptic report section extraction\n",
    "Old code from Arjun: https://github.mskcc.org/knowledgesystems/cdm-pathology/blob/master/main_server.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '/mind_data/fongc2/radiology_met_prediction/')\n",
    "sys.path.insert(0, '../')\n",
    "import re\n",
    "import pandas as pd\n",
    "from dremio_connection import RunDremio\n",
    "from utils_pathology import set_debug_console\n",
    "from key_value_pair_extraction import PathologyKeyValuePairExtraction\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-logan",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_debug_console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlquery = f'''\n",
    "SELECT * FROM \"phi_lake.cdm-data.pathology\".\"table_pathology_surgical_samples_parsed_specimen.csv\"\n",
    "'''\n",
    "sql_accessions = f'''\n",
    "SELECT * FROM \"phi_lake\".\"cdm-data\".pathology.\"path_synoptic_predictions.csv\"\n",
    "'''\n",
    "\n",
    "sql_impact = f'''\n",
    "SELECT * FROM \"phi_lake\".\"cdm-data\".pathology.\"table_pathology_impact_sample_summary_dop_anno.csv\"\n",
    "'''\n",
    "\n",
    "sql_path_dict = f'''\n",
    "SELECT * FROM \"phi_lake\".\"cdm-data\".pathology.\"path_synoptic_dict_all.csv\"\n",
    "'''\n",
    "\n",
    "sql_path_stage = f'''\n",
    "SELECT * FROM \"phi_lake\".\"cdm-data\".pathology.\"path_dx_stage_key_values.csv\"\n",
    "'''\n",
    "\n",
    "sql_path_full = f'''\n",
    "SELECT * FROM \"phi_lake\".\"cdm-data\".pathology.\"table_pathology_clean.csv\"\n",
    "'''\n",
    "\n",
    "\n",
    "user = 'rosalind'\n",
    "pw = 'franklinphoto51'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_path_dx_synoptic = '/mind_data/minio_data/cdm-data/pathology/table_pathology_surgical_samples_parsed_specimen_synoptic.csv'\n",
    "fname_path_dx_key_value = '/mind_data/minio_data/cdm-data/pathology/path_synoptic_dict_all.csv'\n",
    "fname_path_dx_key_value_stage = '/mind_data/minio_data/cdm-data/pathology/path_dx_stage_key_values.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_dremio = RunDremio(user=user, pw=pw)\n",
    "df = obj_dremio.query_data(sql=sqlquery)\n",
    "df_access = obj_dremio.query_data(sql=sql_accessions)\n",
    "df_impact = obj_dremio.query_data(sql=sql_impact)\n",
    "\n",
    "df_path_dict = obj_dremio.query_data(sql=sql_path_dict)\n",
    "df_pathstage = obj_dremio.query_data(sql=sql_path_stage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path_full = obj_dremio.query_data(sql=sql_path_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-flash",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_access['IS_PREDICTION'] == 'False').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path_dict.loc[df_path_dict['ACCESSION_NUMBER'] == 'S21-9532', 'PATH_DX_SPEC_DESC_DICT'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-bidder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pathstage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-senior",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_pathstage.shape)\n",
    "(df_pathstage['RESULT_STAGE'] == '').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-garage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pathstage['COL_NAME_STAGE'].value_counts().head(10).reset_index()\n",
    "# df_pathstage['COL_NAME_STAGE'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcounts = df_pathstage['RESULT_STAGE'].value_counts().reset_index()\n",
    "vcounts.head(11)\n",
    "# text = vcounts['index'].str[:45]\n",
    "# vcounts = vcounts.assign(text=text)\n",
    "# vcounts[['text', 'RESULT_STAGE']].head(12)\n",
    "# df_pathstage['RESULT_STAGE'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-kitchen",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_results = df_pathstage['RESULT_STAGE'].str.findall(r\"[yp]*[TNM]{1}[0-4xX]{1}[a-dA-D]*|[I]{1,3}[a-dA-D]+|[0-4]{1}[a-dA-D]+\")\n",
    "stage_res_len = stage_results.apply(lambda x: len(x))\n",
    "(stage_res_len > 0).sum()\n",
    "df_pathstage = df_pathstage.assign(RESULT_STAGE_CLEAN=stage_results)\n",
    "df_pathstage = df_pathstage.assign(RESULT_STAGE_CLEAN_LEN=stage_res_len)\n",
    "print(df_pathstage.shape)\n",
    "df_pathstage[df_pathstage['RESULT_STAGE_CLEAN_LEN'] > 0].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pathstage.loc[12363]['RESULT_STAGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pathstage_filt = df_pathstage.loc[(df_pathstage['RESULT_STAGE_CLEAN_LEN'] == 0) & ~((df_pathstage['RESULT_STAGE'].isin(['', 'N/A', 'na'])) | (df_pathstage['RESULT_STAGE'].str.lower().str.contains('see')))]\n",
    "print(df_pathstage_filt.shape)\n",
    "df_pathstage_filt.sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pathstage_filt2 = df_pathstage.loc[(df_pathstage['RESULT_STAGE_CLEAN_LEN'] == 0)  ]\n",
    "print(df_pathstage_filt2.shape)\n",
    "df_pathstage_filt2.sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pathstage_filt2_reports = df_pathstage_filt2[['ACCESSION_NUMBER']].drop_duplicates().merge(right=df_path_full, how='left', on='ACCESSION_NUMBER')\n",
    "df_pathstage_filt2_reports.to_csv('path_reports_staging_missing.tsv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-astronomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_num = df_access.loc[df_access['IS_SYNOPTIC'] == '1'].drop_duplicates()\n",
    "access_num_non_syn = df_access.loc[df_access['IS_SYNOPTIC'] == '0'].drop_duplicates()\n",
    "access_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_impact_syn = df_impact.merge(right=access_num, how='left', left_on=['SOURCE_ACCESSION_NUMBER_0', 'SOURCE_SPEC_NUM_0'], right_on=['ACCESSION_NUMBER', 'PATH_DX_SPEC_NUM'])\n",
    "(df_impact_syn['IS_SYNOPTIC'] == '1').sum()/df_impact_syn.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_use = access_num.merge(right=df, how='left', on=['ACCESSION_NUMBER', 'PATH_DX_SPEC_NUM'])\n",
    "df_not_use = access_num_non_syn.merge(right=df, how='left', on=['ACCESSION_NUMBER', 'PATH_DX_SPEC_NUM'])\n",
    "df_use.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-jamaica",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_use.shape)\n",
    "print(df_use.nunique())\n",
    "# df_use.to_csv(fname_path_dx_synoptic, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj_key_value = PathologyKeyValuePairExtraction(fname=fname_path_dx_synoptic, col_dx_spec_desc='PATH_DX_SPEC_DESC', col_out_dict='PATH_DX_SPEC_DESC_DICT', list_col_index=['ACCESSION_NUMBER', 'PATH_DX_SPEC_NUM'], fname_out=fname_path_dx_key_value)\n",
    "# obj_key_value.return_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage = obj_key_value.extract_term(list_key_terms=['STAG', 'AJCC'], key_label='STAGE', fname_save=fname_path_dx_key_value_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-tuition",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = obj_key_value.return_df()\n",
    "df1['PATH_DX_SPEC_DESC_DICT'][10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_use['PATH_DX_SPEC_DESC'].iloc[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_key(item):\n",
    "#     keys = re.findall(r\"([\\\\r\\\\n]{0,3}[- ]*[ \\w\\( \\)\\-]+:)\", item)\n",
    "# #     keys_clean = [x.strip() for x in keys]\n",
    "#     keys_clean = keys\n",
    "#     return keys_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cleanup_for_regex(text):\n",
    "#     for ch in ['\\\\', ';', '`', '*', '_', '{', '}', '?', ':', '[', ']', '(', ')', '<', '>', '#', '+', '-', '.', '!', '$',\n",
    "#                '\"', '\\'']:\n",
    "#         if ch in text:\n",
    "#             text = text.replace(ch, \"\\\\\" + ch)\n",
    "#     return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_value(current_item_updated, next_item_updated, item):\n",
    "#     ''' {key_current:} capture text {key_[current+1]} '''\n",
    "\n",
    "#     reg_exp_to_capture = r\"(?<={0})(.*?)(?={1})\".format(current_item_updated, next_item_updated)\n",
    "\n",
    "#     value_to_capture = re.findall(reg_exp_to_capture, item, re.S | re.M)\n",
    "\n",
    "#     rm_empty_string = list(filter(None, [i for i in value_to_capture[0].splitlines()]))\n",
    "#     filtered_value_to_capture = ','.join(i for i in rm_empty_string)\n",
    "#     filtered_again_value_to_capture = re.findall(\"[^,\\s].*\", filtered_value_to_capture)\n",
    "\n",
    "#     return value_to_capture, filtered_again_value_to_capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_key_in_item(current_item_updated, item):\n",
    "#     '''To avoid duplicate keys in a report: strp keys as you iterate through provided in get_value() '''\n",
    "\n",
    "#     reg_exp_to_del = r\"({0})\".format(current_item_updated)\n",
    "#     item = re.sub(reg_exp_to_del, '', item, 1, re.S)\n",
    "\n",
    "#     return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_key_value_pairs(dx):\n",
    "#     # Get keys \n",
    "#     keys = get_key(item=dx)\n",
    "    \n",
    "#     keys_final = []\n",
    "#     values = []\n",
    "#     for ind, i in enumerate(range(len(keys))):\n",
    "#             try:\n",
    "#                 if i != len(keys) - 1:\n",
    "#                     current_item, next_item = keys[i], keys[i + 1]\n",
    "#                 else:\n",
    "#                     current_item, next_item = keys[i], '\"\"\"'\n",
    "#             except Exception:\n",
    "#                 print('Could not find end key')\n",
    "#                 sys.exit()\n",
    "#             current_item_updated = cleanup_for_regex(current_item)\n",
    "#             next_item_updated = cleanup_for_regex(next_item)\n",
    "\n",
    "#             # Get key\n",
    "#             key = re.findall(\"([A-Za-z0-9].*[^:])\", keys[i])\n",
    "#             if len(key) == 0:\n",
    "#                 key0 = 'EMPTY'\n",
    "#             else:\n",
    "#                 key0 = key[0].strip()\n",
    "#     #         print(key0)\n",
    "#             keys_final.append(key0)\n",
    "\n",
    "#             # Get values\n",
    "#             value0 = 'EMPTY'\n",
    "#             try:\n",
    "#                 value_raw, value = get_value(current_item_updated, next_item_updated, dx)\n",
    "#                 if len(value) == 0:\n",
    "#                     value = 'EMPTY'\n",
    "#                 else:\n",
    "#                     value0 = value[0].strip()\n",
    "#             except:\n",
    "#                 value0 = 'EMPTY'\n",
    "\n",
    "#             values.append(value0)\n",
    "\n",
    "#     # Combine into dict \n",
    "#     list_of_k_v = dict(zip(keys_final, values))\n",
    "# #     list_of_k_v = pd.DataFrame(list(zip(keys_final, values)), columns =['KEYS', 'VALUES'])\n",
    "    \n",
    "#     return list_of_k_v\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-circulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getList(d):\n",
    "#     return d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-laundry",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = df_use['PATH_DX_SPEC_DESC'].iloc[0]\n",
    "print(dx)\n",
    "dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = ['[\\\\r\\\\n]{0,3}[- ]*[ \\w\\(\\)\\-\\+\\;\\,\\'\\.]+[:]+']\n",
    "matches = dict(re.findall(r\"({0})\\s*(.*?)(?=\\s*(?:{0}|$))\".format(\"|\".join(subs)), dx))\n",
    "# matches = re.findall(r\"([\\\\r\\\\n]{0,3}[- ]*[ \\w\\(\\)\\-\\+\\;\\,\\'\\.]+[:]{1})\\s*(.*?)(?=\\s*(?:[\\\\r\\\\n]{0,3}[- ]*[ \\w\\(\\)\\-\\+\\;\\,\\'\\.]+[:]+|$))\", dx)\n",
    "\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_results(dictionary):\n",
    "    rmv_list = [':', '-']\n",
    "    keys = [word.translate({ord(x): ' ' for x in rmv_list}).strip() for word, initial in dictionary.items()]\n",
    "    values = [initial.strip() for initial, initial in dictionary.items()]\n",
    "    dict_out = dict(zip(keys, values))\n",
    "    \n",
    "    return dict_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-ordinance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_key_value_pairs_2(dx):\n",
    "    subs = ['[\\\\r\\\\n]{0,3}[- ]*[ \\w\\(\\)\\-\\+\\;\\,\\'\\.]+[:]+']\n",
    "    regex = re.compile(r\"({0})\\s*(.*?)(?=\\s*(?:{0}|$))\".format(\"|\".join(subs)))\n",
    "    matches = dict(regex.findall(dx))\n",
    "    dict_out = strip_results(dictionary=matches)\n",
    "    \n",
    "    return dict_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_k_v = create_key_value_pairs_2(dx=dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_k_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_use.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_use[df_use['PATH_DX_SPEC_DESC'].notnull()]\n",
    "kv_dict = df_test['PATH_DX_SPEC_DESC'].apply(lambda x: create_key_value_pairs_2(dx=x))\n",
    "df_test = df_test.assign(PATH_DX_SPEC_DESC_DICT=kv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.iloc[410]['PATH_DX_SPEC_DESC_DICT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gather_key_headings(df):\n",
    "series_dict = df_test['PATH_DX_SPEC_DESC_DICT'].apply(lambda x: getList(d=x))\n",
    "df_names = pd.DataFrame(series_dict.to_list())\n",
    "for i,col in enumerate(df_names.columns):\n",
    "    if i == 0:\n",
    "        df_long = df_names[col]\n",
    "    else:\n",
    "        df_long = pd.concat([df_long, df_names[col]], axis=0)\n",
    "\n",
    "df_long1 = df_long.dropna()\n",
    "\n",
    "df_column_names = df_long1.value_counts().reset_index()\n",
    "df_column_names = df_column_names.rename(columns={'index': 'ATTRIBUTE', 0:'COUNTS'})\n",
    "# pct = df_column_names[self._col_counts]/df_column_names[self._col_counts].sum()\n",
    "# df_column_names = df_column_names.assign(pct=pct)\n",
    "\n",
    "#     return df_column_names\n",
    "\n",
    "df_column_names.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[df_test['PATH_DX_SPEC_DESC_DICT'].astype(str).str.contains('|'.join(['STAG', 'AJCC']))]\n",
    "# df_test[df_test['PATH_DX_SPEC_DESC_DICT'].astype(str).str.contains('Histologic Grade')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-header",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_column_names[df_column_names['ATTRIBUTE'].str.upper().str.contains('|'.join(['STAG', 'AJCC']))].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_column_names[df_column_names['ATTRIBUTE'].str.upper().str.contains('|'.join(['GRADE']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 99\n",
    "print(df_test['PATH_DX_SPEC_DESC'].loc[ind])\n",
    "print(df_test['PATH_DX_SPEC_DESC_DICT'].loc[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-precipitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(df_test['PATH_DX_SPEC_DESC_DICT'].tolist(), index=df_test.index)\n",
    "new_df = pd.concat([df_test[['ACCESSION_NUMBER', 'PATH_DX_SPEC_NUM']], new_df], axis=1)\n",
    "new_df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-incentive",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('path_synoptic_dict_all.tsv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_index = ['ACCESSION_NUMBER', 'PATH_DX_SPEC_NUM']\n",
    "logic_cols_use = new_df.columns.str.upper().str.contains('|'.join(['STAG', 'AJCC']))\n",
    "cols_use = new_df.columns[logic_cols_use].to_list()\n",
    "t = new_df[cols_index + cols_use].dropna(how='all', axis=0)\n",
    "t_melt = t.melt(id_vars=cols_index, value_vars=cols_use, value_name='RESULT_STAGE', var_name='COL_NAME_STAGE')\n",
    "t_melt = t_melt[t_melt['RESULT_STAGE'].notnull()]\n",
    "print(t_melt.shape)\n",
    "print(t_melt['COL_NAME_STAGE'].value_counts().head(10))\n",
    "t_melt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "logic_cols_use\n",
    "cols_use = new_df.columns[logic_cols_use]\n",
    "cols_use.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-patrol",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_missing = t_melt[t_melt['RESULT_STAGE'] == 'EMPTY'].merge(right=df_use, how='left', on=['ACCESSION_NUMBER' ,'PATH_DX_SPEC_NUM'])\n",
    "t_notmissing = t_melt[t_melt['RESULT_STAGE'] != 'EMPTY'].merge(right=df_use, how='left', on=['ACCESSION_NUMBER' ,'PATH_DX_SPEC_NUM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_missing['PATH_DX_SPEC_DESC'].iloc[1]\n",
    "# print(t_notmissing['PATH_DX_SPEC_DESC'].iloc[1])\n",
    "t_missing['PATH_DX_SPEC_DESC'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_impact_m = df_impact.merge(right=t_melt, how='left', left_on=['SOURCE_ACCESSION_NUMBER_0', 'SOURCE_SPEC_NUM_0'], right_on=['ACCESSION_NUMBER', 'PATH_DX_SPEC_NUM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_impact_m['RESULT_STAGE'].notnull() & ).sum()/df_impact_m.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_impact_m[df_impact_m['RESULT_STAGE'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df = pd.concat(pd.DataFrame({'name':k, 'value':v}) for k, v in x.items())\n",
    "# df['index'] = df.groupby('name').cumcount().add(1)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_surgical = df[df['ACCESSION_NUMBER'].str.contains('S')].reset_index(drop=True)\n",
    "df_surgical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_kv(df):\n",
    "    for i in range(df.shape[0]):\n",
    "        current_kv_df = create_key_value_pairs(df['PATH_DX_SPEC_DESC'].iloc[i])\n",
    "        current_kv_df = current_kv_df.assign(ACCESSION_NUMBER=df['ACCESSION_NUMBER'].iloc[i])\n",
    "        current_kv_df = current_kv_df.assign(PATH_DX_SPEC_NUM=df['PATH_DX_SPEC_NUM'].iloc[i])\n",
    "\n",
    "        if i == 0:\n",
    "            df_kv_final = current_kv_df.copy()\n",
    "        else:\n",
    "            df_kv_final = pd.concat([df_kv_final, current_kv_df], axis=0)\n",
    "    #     print(df_test['PATH_DX_SPEC_DESC'][i])\n",
    "    #     print('----')\n",
    "    return df_kv_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kv_final = get_df_kv(df=df_test)\n",
    "df_kv_final.to_csv('pathology_spec_desc_key_value.tsv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kv_final.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-color",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
