{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    " test_synoptic_report_classifier\n",
    "\n",
    " By Chris Fong - MSKCC 2021\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '/mind_data/fongc2/pathology_report_segmentation/')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import constants_darwin_pathology as c_dar\n",
    "from utils_pathology import set_debug_console\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from pathology_synoptic_logistic_model import SynopticReportClassifier\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Console settings\n",
    "set_debug_console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_syn = 'IS_SYNOPTIC'\n",
    "cols_feat = ['FEATURE1', 'FEATURE2', 'FEATURE3']\n",
    "pathname = c_dar.pathname\n",
    "fname_save = c_dar.fname_path_synoptic\n",
    "pathfilename_save = os.path.join(pathname, fname_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data\n",
    "fname = c_dar.fname_darwin_path_clean_parsed_specimen\n",
    "pathfilename_data = os.path.join(pathname, fname)\n",
    "df_path_long = pd.read_csv(pathfilename_data, header=0, low_memory=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = c_dar.fname_path_synoptic_labels\n",
    "pathfilename_labels = os.path.join(pathname, fname)\n",
    "df_path_labels = pd.read_csv(pathfilename_labels, header=0, low_memory=False, sep=',')\n",
    "df_path_labels = df_path_labels[df_path_labels[col_syn].notnull()]\n",
    "df_path_labels[col_syn] = df_path_labels[col_syn].astype(int)\n",
    "df_path_labels.drop(columns=['PATH_DX_SPEC_DESC'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path_labels.head()\n",
    "# df_path_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "# Create features\n",
    "feature1 = df_path_long['PATH_DX_SPEC_DESC'].str.count('- ')\n",
    "feature2 = df_path_long['PATH_DX_SPEC_DESC'].str.count(':')\n",
    "feature3 = df_path_long['PATH_DX_SPEC_DESC'].str.len()\n",
    "df_path_long = df_path_long.assign(FEATURE1=feature1)\n",
    "df_path_long = df_path_long.assign(FEATURE2=feature2)\n",
    "df_path_long = df_path_long.assign(FEATURE3=feature3)\n",
    "df_path_long = df_path_long.merge(right=df_path_labels, how='left', on=['ACCESSION_NUMBER', 'PATH_DX_SPEC_NUM'])\n",
    "\n",
    "\n",
    "df = df_path_long[['ACCESSION_NUMBER', 'PATH_DX_SPEC_NUM', col_syn] + cols_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create df for training features and labels\n",
    "logic_keep = df[cols_feat].notnull().sum(axis=1) == 3\n",
    "logic_labeled = df[col_syn].notnull()\n",
    "df_training = df[logic_keep & logic_labeled].reset_index(drop=True)\n",
    "df_training = df_training.assign(IS_PREDICTION=False)\n",
    "df_training_features = df_training[cols_feat]\n",
    "data_norm = (df_training_features - df_training_features.mean(axis=0))/df_training_features.std(axis=0)\n",
    "df_training_labels = df_training[col_syn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross validation by taking all feature data and separating into training and testing data\n",
    "# Init cross validation variables\n",
    "folds = 10\n",
    "logisticRegr = LogisticRegression(solver='lbfgs')\n",
    "num_classes = 2\n",
    "Cknown = np.zeros(shape=(num_classes, 1))\n",
    "Cmat = np.zeros(shape=(num_classes, num_classes))\n",
    "\n",
    "kf = KFold(n_splits=folds)\n",
    "\n",
    "scores = [None] * folds\n",
    "precisions = [None] * folds\n",
    "precision_all = [None] * folds\n",
    "i = 0\n",
    "j = 0\n",
    "for train_index, test_index in kf.split(df_training_features):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = df_training_features.loc[train_index], df_training_features.loc[test_index]\n",
    "    y_train, y_test = df_training_labels[train_index], df_training_labels[test_index]\n",
    "    \n",
    "    df_index = df_training.loc[X_test.index, ['ACCESSION_NUMBER', 'PATH_DX_SPEC_NUM']]\n",
    "    \n",
    "    # Perform classification\n",
    "    logisticRegr.fit(X_train, y_train)\n",
    "    y_pred = logisticRegr.predict(X_test)\n",
    "\n",
    "    # Determine accuracy and precision\n",
    "    y_actual = np.array(y_test)\n",
    "    \n",
    "    df_pred_comp = pd.DataFrame([y_actual, y_pred]).T.rename(columns={0:'Actual', 1: 'Predicted'})\n",
    "    df_pred_comp = df_pred_comp.set_index(df_index.index, drop=True)\n",
    "    df_pred_comp = pd.concat([df_index, df_pred_comp], axis=1)\n",
    "    logic_cmp = df_pred_comp['Actual'] != df_pred_comp['Predicted']\n",
    "    df_pred_comp = df_pred_comp.assign(Incorrect=logic_cmp)\n",
    "    \n",
    "    df_wrong_cases = df_pred_comp[df_pred_comp['Incorrect'] == True]\n",
    "    if df_wrong_cases.shape[0] > 0:\n",
    "        if j == 0:\n",
    "            df_wrong_cases_f = df_wrong_cases.copy()\n",
    "            j = 1\n",
    "        else:\n",
    "            df_wrong_cases_f = pd.concat([df_wrong_cases_f, df_wrong_cases], axis=0)\n",
    "\n",
    "    C = confusion_matrix(y_actual, y_pred)\n",
    "\n",
    "    # The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives\n",
    "    average_precision = precision_score(y_actual, y_pred, average='weighted')\n",
    "    precision_organ = precision_score(y_actual, y_pred, average=None)\n",
    "    # The set of labels predicted for a sample must exactly match the corresponding set of labels in y_true.\n",
    "    score = accuracy_score(y_true=y_test, y_pred=y_pred, normalize=True)\n",
    "    scores[i] = score\n",
    "    precisions[i] = average_precision\n",
    "    precision_all[i] = precision_organ\n",
    "\n",
    "    sumC = np.sum(C, axis=1)\n",
    "    sumC = sumC.reshape(num_classes, 1)\n",
    "    Cknown += sumC\n",
    "    Cmat = Cmat + C\n",
    "    i += 1\n",
    "    \n",
    "df_wrong_cases_f = df_wrong_cases_f.drop_duplicates()\n",
    "df_wrong_cases_f = df_path_labels.merge(right=df_wrong_cases_f, how='right', on=['ACCESSION_NUMBER', 'PATH_DX_SPEC_NUM'])\n",
    "df_wrong_cases_f;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix heatmap \n",
    "label_names = ['Synoptic', 'Not Synoptic']\n",
    "score_avg = np.mean(scores)\n",
    "precision_avg = np.mean(precisions)\n",
    "precision_organ = pd.DataFrame(precision_all, columns=label_names)\n",
    "Cknown1 = np.tile(Cknown, num_classes)\n",
    "Cmat1 = np.divide(Cmat, Cknown1)\n",
    "Cmat1_d = pd.DataFrame(Cmat1, columns=['Predicted ' + x for x in label_names], index=['True ' + x for x in label_names])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(df_training_labels))\n",
    "plt.xticks(tick_marks, df_training_labels)\n",
    "plt.yticks(tick_marks, df_training_labels)\n",
    "# create heatmap\n",
    "sns.heatmap(Cmat1_d, annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cmat\n",
    "Cknown1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "logit_roc_auc = roc_auc_score(y_test, logisticRegr.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logisticRegr.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PCA for visualization\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(df_training_features)\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n",
    "principalDf = principalDf.assign(IS_SYNOPTIC=df_training_labels)\n",
    "principalDf = principalDf.replace(to_replace={col_syn: {1: label_names[0], 0: label_names[1]}})\n",
    "\n",
    "# Plot PCA results\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA for Synoptic Report Classification', fontsize = 14)\n",
    "colors = ['g', 'b']\n",
    "for target, color in zip(label_names, colors):\n",
    "    indicesToKeep = principalDf[col_syn] == target\n",
    "    ax.scatter(principalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , principalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(label_names)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-capability",
   "metadata": {},
   "source": [
    "---\n",
    "## Create full model from all labels and predict on unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-tractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logistic reg model\n",
    "## Compute test path files\n",
    "logic_not_labeled = df[col_syn].isnull()\n",
    "df_validation = df.loc[logic_not_labeled & logic_keep].copy()\n",
    "x_validation = df_validation[cols_feat]\n",
    "\n",
    "# all parameters not specified are set to their defaults\n",
    "logisticRegr = LogisticRegression(solver='lbfgs')\n",
    "logisticRegr.fit(df_training_features, df_training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_features.head()\n",
    "x_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = logisticRegr.predict(x_validation)\n",
    "df_validation = df_validation.assign(IS_SYNOPTIC=predicted)\n",
    "df_validation = df_validation.assign(IS_PREDICTION=True)\n",
    "\n",
    "pred_counts = df_validation['IS_SYNOPTIC'].value_counts()\n",
    "\n",
    "# Percentage of reports predicted to be synoptic\n",
    "pct_pred_syn = (pred_counts[pred_counts.index == 1].iloc[0])/pred_counts.sum()\n",
    "pct_pred_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-liver",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "df_label_synoptic = pd.concat([df_training, df_validation], axis=0, sort=False)[col_keep].reset_index(drop=True)\n",
    "df_label_synoptic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-lesson",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_synoptic['IS_PREDICTION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_synoptic['IS_SYNOPTIC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_syn = SynopticReportClassifier(fname_parsed_spec=pathfilename_data, \n",
    "                                   fname_synoptic_labels=pathfilename_labels,\n",
    "                                   fname_save=pathfilename_save)\n",
    "df_results = obj_syn.return_synoptic()\n",
    "print(df_results['IS_SYNOPTIC'].value_counts())\n",
    "print(df_results['IS_PREDICTION'].value_counts())\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-utility",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
